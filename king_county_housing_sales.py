# -*- coding: utf-8 -*-
"""King County Housing Sales.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BINC_z-4olyKY5K-CeAIgZxnUP5sfN8n

#King County Housing Sales

### EDA
"""

# Load core libraries
import numpy as np
import pandas as pd
import statsmodels.api as sm
from statsmodels.tsa.arima.model import ARIMA
from dateutil.relativedelta import relativedelta

# Load data
df = pd.read_csv("/content/kc_house_data(1).csv")
# Show first 5 rows
df.head()

# Show dataset shape (rows, columns)
df.shape

# Show data types of each column
df.dtypes

# Show number of missing values per column
df.isnull().sum()

# Show number of duplicated rows
df.duplicated().sum()

# Show summary statistics for numeric columns
df.describe()

# Show summary statistics for price column only
df["price"].describe()

"""### EDA Visualization"""

import plotly.express as px

# Plot - Histogram of house prices
fig = px.histogram(
    df,
    x='price',       # column to plot
    nbins=50,        # number of bins (bars)
    title='Distribution of House Prices' # chart title
)

# Show plot
fig.show()

import pandas as pd
import plotly.express as px

# Create bins for living area (0 to 10,000 with step 500)
df['sqft_group'] = pd.cut(df['sqft_living'], bins=range(0, 10000, 500))

# Convert bins to string for plotting
df['sqft_group_str'] = df['sqft_group'].astype(str)

# Calculate average price per living area group
avg_price = df.groupby('sqft_group_str')['price'].mean().reset_index()

# Plot - line chart of average price by living area group
fig = px.line(
    avg_price,
    x='sqft_group_str',   # x-axis: living area group
    y='price',            # y-axis: average price
    title='Average Price by Living Area',
    labels={'sqft_group_str': 'Living Area (sqft)', 'price': 'Average Price'}
)

# Show plot
fig.show()

import plotly.express as px

# Compute average price per bedroom
avg_price_bedrooms = df.groupby("bedrooms")["price"].mean().reset_index()

fig = px.bar(
    avg_price_bedrooms,
    x="bedrooms",
    y="price",
    text="price",  # show value on top
    title="Average House Price by Number of Bedrooms",
    labels={"bedrooms": "Number of Bedrooms", "price": "Average Price"}
)

# Format text on bars
fig.update_traces(texttemplate='%{text:.0f}', textposition='outside')

fig.show()

avg_price_bathrooms = df.groupby("bathrooms")["price"].mean().reset_index()

fig = px.bar(
    avg_price_bathrooms,
    x="bathrooms",
    y="price",
    text="price",
    title="Average House Price by Number of Bathrooms",
    labels={"bathrooms": "Number of Bathrooms", "price": "Average Price"}
)


fig.update_traces(texttemplate='$%{text:,.0f}', textposition='outside')

fig.update_layout(yaxis_tickformat="$,.0f")
fig.show()

import plotly.express as px

# Compute average price per year built
avg_price_by_year = df.groupby("yr_built")["price"].mean().reset_index()

# Line chart of average price over years
fig = px.line(
    avg_price_by_year,
    x="yr_built",
    y="price",
    title="Average House Price by Year Built",
    labels={"yr_built": "Year Built", "price": "Average Price"}
)

fig.show()

fig = px.box(
    df, x="grade", y="price", points="outliers",
    title="Price Distribution by Grade"
)
fig.update_layout(yaxis_tickformat="$,.0f")
fig.show()

avg_by_floors = df.groupby("floors")["price"].mean().reset_index()
fig = px.line(
    avg_by_floors, x="floors", y="price",
    markers=True, title="Average Price by Number of Floors"
)
fig.update_layout(yaxis_tickformat="$,.0f")
fig.show()

fig = px.scatter_mapbox(
    df,
    lat="lat", lon="long",
    color="price",
    size="sqft_living",
    hover_data=["zipcode", "bedrooms", "bathrooms", "sqft_living", "price"],
    zoom=9,
    height=600,
    title="Homes Map â€“ Price & Size"
)


fig.update_layout(
    mapbox_style="open-street-map",
    coloraxis_colorbar_title="Price"
)

fig.show()

avg_price_waterfront = df.groupby("waterfront")["price"].mean().reset_index()

fig = px.bar(
    avg_price_waterfront,
    x="waterfront",
    y="price",
    text="price",
    title="Average House Price by Waterfront",
    labels={"waterfront": "Waterfront (0 = No, 1 = Yes)", "price": "Average Price"}
)

fig.update_traces(texttemplate='$%{text:,.0f}', textposition='outside')
fig.update_layout(yaxis_tickformat="$,.0f")
fig.show()

avg_price_view = df.groupby("view")["price"].mean().reset_index()

fig = px.pie(
    avg_price_view,
    names="view",
    values="price",
    title="Average Price Share by View",
    hole=0.4
)
fig.show()

"""### Cleaning & Preprocessing"""

# Rename columns to simpler names
df = df.rename(columns={
    "date": "sale_date",
    "bedrooms": "num_bedrooms",
    "bathrooms": "num_bathrooms",
    "sqft_living": "living_sqft",
    "sqft_lot": "lot_sqft",
    "floors": "num_floors",
    "sqft_above": "above_sqft",
    "sqft_basement": "basement_sqft",
    "yr_built": "year_built",
    "yr_renovated": "year_renovated",
    "sqft_living15": "living_sqft15",
    "sqft_lot15": "lot_sqft15",
}, errors="ignore") # ignore if column doesn't exist

# Convert sale_date column to datetime format
df['sale_date'] = pd.to_datetime(df['date'], errors='coerce') if 'sale_date' not in df.columns and 'date' in df.columns else pd.to_datetime(df['sale_date'], errors='coerce')

# Convert sale_date column to datetime
base_cols = [
    'price',
    'living_sqft',
    'grade',
    'num_bathrooms',
    'num_bedrooms',
    'condition',
    'waterfront',
    'sale_date'
]

for c in base_cols:
    if c != 'sale_date':
        df[c] = pd.to_numeric(df[c], errors='coerce')
    else:
        df[c] = pd.to_datetime(df[c], errors='coerce')  # Convert to datetime

# Drop rows with NaN in any of the base columns
df = df.dropna(subset=base_cols)

# Drop rows with missing price or sale_date
df['log_price'] = np.log(df['price'])

# Show first 5 records
df.head()

df.to_csv("cleaned_file.csv", index=False, encoding="utf-8-sig")

"""### **Split & Trend**"""

# Sort dataset by sale_date
df = df.sort_values('sale_date').copy()

# Split data into train and test
cutoff = pd.Timestamp('2015-01-01')
train = df[df['sale_date'] < cutoff].copy()
test  = df[df['sale_date'] >= cutoff].copy()

# Extract year, month, and year-month from sale_date
train['ym'] = train['sale_date'].dt.to_period('M')
test['ym']  = test['sale_date'].dt.to_period('M')
train["year"] = train["sale_date"].dt.year
train["month"] = train["sale_date"].dt.month
test["year"] = test["sale_date"].dt.year
test["month"] = test["sale_date"].dt.month

trend_train = train.groupby('ym')['log_price'].mean().rename('market_trend')

# Add market trend to train & test
train = train.merge(trend_train, on='ym', how='left')
test  = test.merge(trend_train, on='ym', how='left')

# Fill missing trend in test with last known value
last_trend = trend_train.iloc[-1]
test['market_trend'] = test['market_trend'].fillna(last_trend)

# Select features and drop rows with missing values
features = ['living_sqft','grade','num_bathrooms','num_bedrooms',
            'condition','waterfront','market_trend','year','month']
need_cols = features + ['log_price']
train = train.dropna(subset=need_cols)
test  = test.dropna(subset=need_cols)

train.shape, test.shape

"""### Model"""

# Build OLS model with selected features
X_train = sm.add_constant(train[features].astype(float), has_constant='add')
y_train = train['log_price'].astype(float)
ols_model = sm.OLS(y_train, X_train).fit()

# Align test features with train and predict log_price
X_test = sm.add_constant(test[features].astype(float), has_constant='add')
X_test = X_test.reindex(columns=X_train.columns, fill_value=0.0)
y_test_log = test['log_price'].astype(float)
y_pred_log = ols_model.predict(X_test)

X_train_columns = list(X_train.columns)

"""### Trying the model"""

# quick table: actual vs predicted (prices)
preds_df = pd.DataFrame({
    "actual_price": np.exp(y_test_log).astype(float),
    "pred_price":  np.exp(y_pred_log).astype(float)
})
preds_df["abs_error"] = (preds_df["pred_price"] - preds_df["actual_price"]).abs()
preds_df["pct_error"] = (preds_df["abs_error"] / preds_df["actual_price"]) * 100
preds_df.head(10)

# simple scatter: predicted vs actual
import matplotlib.pyplot as plt

y_true = preds_df["actual_price"].values
y_hat  = preds_df["pred_price"].values

plt.figure()
plt.scatter(y_true, y_hat, s=10, alpha=0.7)
lim_min = float(min(y_true.min(), y_hat.min()))
lim_max = float(max(y_true.max(), y_hat.max()))
plt.plot([lim_min, lim_max], [lim_min, lim_max], linewidth=1)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("Predicted vs Actual")
plt.show()

# quick sample predictions (first 5 rows)
sample_X = test[features].head(5).copy()
sample_X = sm.add_constant(sample_X.astype(float), has_constant='add')
sample_X = sample_X.reindex(columns=X_train.columns, fill_value=0.0)
sample_pred_log = ols_model.predict(sample_X)
smear = np.exp(getattr(ols_model, "mse_resid", 0)/2.0)
sample_pred_price = np.exp(sample_pred_log) * smear
pd.DataFrame({
    "pred_price": sample_pred_price.astype(float)
})

print("Enter values:")
living_sqft  = float(input("living_sqft: "))
grade        = int(input("grade (1-13): "))
num_bathrooms= float(input("num_bathrooms: "))
num_bedrooms = int(input("num_bedrooms: "))
condition    = int(input("condition (1-5): "))
waterfront   = int(input("waterfront (0/1): "))
year         = int(input("sale year (e.g., 2015): "))
month        = int(input("sale month (1-12): "))

# 1)# 1) Build row, ensure year and month exist

row = {
    "living_sqft":  living_sqft,
    "grade":        grade,
    "num_bathrooms":num_bathrooms,
    "num_bedrooms": num_bedrooms,
    "condition":    condition,
    "waterfront":   waterfront,
    "year":         year,
    "month":        month
}

df_row = pd.DataFrame([row])


ym = pd.Period(f"{year}-{month:02d}", freq="M")
mt = trend_train.get(ym, default=last_trend)
df_row["market_trend"] = float(mt)


for col in features:
    if col not in df_row.columns:
        df_row[col] = 0.0

X = sm.add_constant(df_row[features].astype(float), has_constant="add")
X = X.reindex(columns=X_train_columns, fill_value=0.0)

y_log = float(ols_model.predict(X).iloc[0])
smear = np.exp(getattr(ols_model, "mse_resid", 0) / 2.0)
pred_price = float(np.exp(y_log) * smear)

print(round(pred_price, 2))

"""### Evaluation"""

# 7b) Accuracy only (from test set)
smear = np.exp(getattr(ols_model, "mse_resid", 0) / 2.0)
y_true_test = np.exp(y_test_log).astype(float)
y_pred_test = (np.exp(y_pred_log) * smear).astype(float)
mape_test = float(np.mean(np.abs(y_true_test - y_pred_test) / y_true_test) * 100)
acc_test = 100.0 - mape_test
print(f"{acc_test:.1f}%")

# Regression evaluation: log metrics + original scale with smearing
import numpy as np
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

def regression_report(y_true_log, y_pred_log, model=None, verbose=True):
    y_true_log = np.asarray(y_true_log).ravel()
    y_pred_log = np.asarray(y_pred_log).ravel()

    r2_log   = r2_score(y_true_log, y_pred_log)
    rmse_log = mean_squared_error(y_true_log, y_pred_log)
    mae_log  = mean_absolute_error(y_true_log, y_pred_log)
        # Ensure inputs are 1D arrays

    y_true = np.exp(y_true_log)
    y_pred = np.exp(y_pred_log)
    # Metrics on log scale

    smear = np.exp(getattr(model, "mse_resid", np.var(y_true_log - y_pred_log)) / 2.0)
    y_pred_smear = y_pred * smear
 # Metrics on original price scale
    rmse = mean_squared_error(y_true, y_pred_smear)
    mae  = mean_absolute_error(y_true, y_pred_smear)
    mape = np.mean(np.abs(y_true - y_pred_smear) / y_true) * 100
    acc  = 100 - mape

    if verbose:
        print(f"RÂ² (log): {r2_log:.3f}")
        print(f"RMSE (log): {rmse_log:.3f}")
        print(f"MAE  (log): {mae_log:.3f}")
        print("-"*40)
        print(f"RMSE (price): {rmse:,.0f}")
        print(f"MAE  (price): {mae:,.0f}")
        print(f"MAPE: {mape:.1f}%")
        print(f"Accuracy (â‰ˆ): {acc:.1f}%")

    return {
        "R2_log": round(r2_log, 3),
        "RMSE_log": round(rmse_log, 3),
        "MAE_log": round(mae_log, 3),
        "RMSE_price": float(rmse),
        "MAE_price": float(mae),
        "MAPE_%": round(mape, 1),
        "Accuracy_%": round(acc, 1),
    }

regression_report(y_test_log, y_pred_log, model=ols_model)

"""### Save the Model"""

import pickle
# Save trained OLS model

with open("ols_model.pkl", "wb") as f:
    pickle.dump(ols_model, f)

with open("trend_train.pkl", "wb") as f:
    pickle.dump(trend_train, f)

meta = {
    "last_trend": last_trend,
    "features": features,
    "X_train_columns": X_train_columns
}
with open("meta.pkl", "wb") as f:
    pickle.dump(meta, f)

"""### Dashbored"""

!pip install -q streamlit pyngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile dashboard.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import plotly.express as px
# import re, pickle, statsmodels.api as sm
# 
# st.set_page_config(page_title="House Sales in King County Dashboard", layout="wide")
# 
# # chart colors
# COLORS = ["#00C767", "#0B3D0B"]  # rich green + dark green (not neon)
# PIE_COLORS = ["#1B5E20", "#2E7D32", "#66BB6A", "#A5D6A7"]  # softer greens
# BG_PAPER = "rgba(0,0,0,0)"
# BG_PLOT  = "rgba(0,0,0,0)"
# FONT_COL = "#FFFFFF"
# GRID_COL = "rgba(102,187,106,0.35)"  # soft green grid
# 
# def apply_dark_layout(fig, show_legend=True):
#     fig.update_layout(
#         template="simple_white",
#         paper_bgcolor=BG_PAPER,
#         plot_bgcolor=BG_PLOT,
#         font=dict(color=FONT_COL),
#         legend_title_text="",
#         legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0) if show_legend else dict(),
#         margin=dict(t=60, r=20, b=40, l=60)
#     )
#     fig.update_xaxes(showgrid=True, gridcolor=GRID_COL, zeroline=False, linecolor="#2E7D32")
#     fig.update_yaxes(showgrid=True, gridcolor=GRID_COL, zeroline=False, linecolor="#2E7D32")
#     return fig
# 
# st.markdown("""
# <style>
# .stApp, [data-testid="stSidebar"] { background-color: #000000; color: #FFFFFF; }
# a { color: #66BB6A !important; }
# [data-testid="stSlider"] [data-baseweb="slider"] > div:nth-child(1) { background-color: rgba(11,61,11,0.25) !important; }
# [data-testid="stSlider"] [data-baseweb="slider"] > div [class*="inner"] { background-color: #0B3D0B !important; }
# [data-testid="stSlider"] [data-baseweb="slider"] [role="slider"] {
#     background-color: #0B3D0B !important; border: 2px solid #0B3D0B !important; box-shadow: 0 0 0 4px rgba(11,61,11,0.25) !important;
# }
# [data-testid="stMetric"] { background: transparent; border: none; padding: 14px 16px; }
# [data-testid="stMetric"] [data-testid="stMetricLabel"],
# [data-testid="stMetric"] [data-testid="stMetricValue"] { color: #FFFFFF !important; }
# </style>
# """, unsafe_allow_html=True)
# 
# # load data
# df = pd.read_csv("/content/cleaned_file.csv")
# date_col = "sale_date" if "sale_date" in df.columns else "date"
# df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
# df = df.rename(columns={date_col: "sale_date"})
# df = df.dropna(subset=["sale_date", "price"]).copy()
# df["sale_ym"] = df["sale_date"].dt.to_period("M").dt.to_timestamp()
# 
# # extra columns
# if "num_bedrooms" in df.columns:
#     df["num_bedrooms_int"] = pd.to_numeric(df["num_bedrooms"], errors="coerce").astype("Int64")
# if "num_bathrooms" in df.columns:
#     df["num_bathrooms_int"] = pd.to_numeric(df["num_bathrooms"], errors="coerce").round().astype("Int64")
# if "waterfront" in df.columns:
#     df["waterfront_int"] = pd.to_numeric(df["waterfront"], errors="coerce").fillna(0).astype(int)
#     df["waterfront_label"] = df["waterfront_int"].map({1: "Waterfront", 0: "Non-waterfront"})
# else:
#     df["waterfront_label"] = "Unknown"
# 
# # title
# st.title("King County Housing Sales Dashboard")
# 
# with st.expander("Dataset Description"):
#     st.markdown("""
# This dataset contains detailed information about house sales in King County.
# It includes the following fields:
# 
# - **Sale date**: The date when the property was sold.
# - **Price**: The sale price of the property.
# - **Bedrooms and bathrooms**: The number of bedrooms and bathrooms in the house.
# - **Living and lot square footage**: The interior living space and the total lot size.
# - **Floors, waterfront, and view**: Structural details, whether the property is on the waterfront, and the quality of the view.
# - **Market trend**: Used for analyzing how prices and demand have changed over time.
# """)
# 
# # filters
# st.sidebar.header("Filters")
# ym_all = sorted(df["sale_ym"].dropna().unique().tolist())
# ym_all = [pd.Timestamp(t).to_pydatetime() for t in ym_all] or [pd.Timestamp("2014-01-01"), pd.Timestamp("2015-12-01")]
# min_ym, max_ym = min(ym_all), max(ym_all)
# ym_range = st.sidebar.slider("Sale Date (YM)", min_value=min_ym, max_value=max_ym, value=(min_ym, max_ym), format="YYYY-MM")
# 
# # price filter
# min_price, max_price = int(df["price"].min()), int(df["price"].max())
# price_range = st.sidebar.slider(
#     "Price Range ($)",
#     min_value=min_price,
#     max_value=max_price,
#     value=(min_price, max_price),
#     step=10000
# )
# 
# beds = ["All"] + (sorted(df["num_bedrooms_int"].dropna().unique().tolist()) if "num_bedrooms_int" in df.columns else [])
# baths = ["All"] + (sorted(df["num_bathrooms_int"].dropna().unique().tolist()) if "num_bathrooms_int" in df.columns else [])
# sel_beds  = st.sidebar.selectbox("Bedrooms", beds)
# sel_baths = st.sidebar.selectbox("Bathrooms", baths)
# 
# # apply filters
# f = df[
#     (df["sale_ym"] >= pd.Timestamp(ym_range[0])) &
#     (df["sale_ym"] <= pd.Timestamp(ym_range[1])) &
#     (df["price"] >= price_range[0]) &
#     (df["price"] <= price_range[1])
# ].copy()
# 
# if sel_beds  != "All" and "num_bedrooms_int" in f.columns:
#     f = f[f["num_bedrooms_int"] == int(sel_beds)]
# if sel_baths != "All" and "num_bathrooms_int" in f.columns:
#     f = f[f["num_bathrooms_int"] == int(sel_baths)]
# 
# def human_format(num):
#     for unit in ["", "K", "M", "B", "T"]:
#         if abs(num) < 1000.0:
#             return f"{num:3.1f}{unit}"
#         num /= 1000.0
#     return f"{num:.1f}P"
# 
# # KPIs
# c1, c2, c3, c4 = st.columns(4)
# c1.metric("Total Sales", f"${human_format(f['price'].sum())}")
# c2.metric("Avg Price",    f"${human_format(f['price'].mean() if len(f) else 0)}")
# c3.metric("Median Price", f"${human_format(f['price'].median() if len(f) else 0)}")
# c4.metric("Homes Sold",   human_format(len(f)))
# 
# 
# # row 1: line
# r1c1 = st.columns(1)[0]
# with r1c1:
#     st.subheader("Monthly Average Sale Price")
#     monthly = f.groupby("sale_ym", as_index=False)["price"].mean().sort_values("sale_ym")
#     if len(monthly):
#         fig = px.line(monthly, x="sale_ym", y="price", markers=True, color_discrete_sequence=[COLORS[0]])
#         fig.update_traces(marker=dict(size=6, line=dict(width=0)))
#         fig.update_layout(xaxis_title="Year-Month", yaxis_title="Avg Price ($)", hovermode="x unified")
#         fig.update_yaxes(tickformat=",.0f")
#         st.plotly_chart(apply_dark_layout(fig, show_legend=False), use_container_width=True)
# 
# # row 2: scatter + bar
# r2c1, r2c2 = st.columns(2)
# with r2c1:
#     st.subheader("Price vs Living Sqft ")
#     if {"living_sqft","price"}.issubset(f.columns):
#         sc = f.dropna(subset=["living_sqft","price"])
#         if len(sc):
#             fig = px.scatter(sc, x="living_sqft", y="price", opacity=0.55, color_discrete_sequence=[COLORS[1]])
#             z = np.polyfit(sc["living_sqft"], sc["price"], 2)
#             p = np.poly1d(z)
#             x_sorted = np.linspace(sc["living_sqft"].min(), sc["living_sqft"].max(), 200)
#             fig.add_scatter(x=x_sorted, y=p(x_sorted), mode="lines", line=dict(color=COLORS[0], width=3), name="Poly Fit")
#             fig.update_layout(xaxis_title="Living Sqft", yaxis_title="Price ($)")
#             fig.update_yaxes(tickformat=",.0f")
#             st.plotly_chart(apply_dark_layout(fig), use_container_width=True)
# 
# with r2c2:
#     st.subheader("Avg Price by Bedrooms & Bathrooms")
#     bars = []
#     if "num_bedrooms_int" in f.columns:
#         b = f.dropna(subset=["price","num_bedrooms_int"]).groupby("num_bedrooms_int", as_index=False)["price"].mean()
#         if len(b):
#             b["Category"] = "Bedrooms"; b["Value"] = b["num_bedrooms_int"].astype(str); bars.append(b[["Category","Value","price"]])
#     if "num_bathrooms_int" in f.columns:
#         t = f.dropna(subset=["price","num_bathrooms_int"]).groupby("num_bathrooms_int", as_index=False)["price"].mean()
#         if len(t):
#             t["Category"] = "Bathrooms"; t["Value"] = t["num_bathrooms_int"].astype(str); bars.append(t[["Category","Value","price"]])
#     if bars:
#         df_bar = pd.concat(bars)
#         fig_bar = px.bar(df_bar, x="Value", y="price", color="Category", barmode="group", text_auto=".2s",
#                          color_discrete_sequence=COLORS)
#         fig_bar.update_layout(xaxis_title="Count", yaxis_title="Avg Price ($)")
#         fig_bar.update_yaxes(tickformat=",.0f")
#         st.plotly_chart(apply_dark_layout(fig_bar), use_container_width=True)
# 
# # row 3: bars + pie
# r3c1, r3c2 = st.columns(2)
# with r3c1:
#     st.subheader("Average Price by Waterfront")
#     if "waterfront_label" in f.columns and f["waterfront_label"].nunique() > 1:
#         wf = f.dropna(subset=["price"]).groupby("waterfront_label", as_index=False)["price"].mean()
#         if len(wf):
#             fig = px.bar(
#                 wf, x="waterfront_label", y="price", text_auto=".2s",
#                 color="waterfront_label", color_discrete_sequence=COLORS
#             )
#             fig.update_layout(
#                 xaxis_title="Waterfront",
#                 yaxis_title="Avg Price ($)",
#                 xaxis=dict(title="", tickmode="array", tickvals=wf["waterfront_label"]),
#                 bargap=0.4,
#                 uniformtext_minsize=12,
#                 uniformtext_mode="hide"
#             )
#             fig.update_yaxes(tickformat=",.0f")
#             st.plotly_chart(apply_dark_layout(fig, show_legend=False), use_container_width=True)
# 
# with r3c2:
#     st.subheader("Average Price Share by View")
#     if "view" in f.columns:
#         vg = f.dropna(subset=["view","price"]).groupby("view", as_index=False)["price"].mean().sort_values("view")
#         if len(vg):
#             fig = px.pie(vg, names="view", values="price", hole=0.3, color_discrete_sequence=PIE_COLORS)
#             fig.update_traces(textinfo="percent+label")
#             st.plotly_chart(apply_dark_layout(fig), use_container_width=True)
# 
# # row 4: preview
# r4c1 = st.columns(1)[0]
# with r4c1:
#     st.subheader("Data Preview")
#     st.dataframe(df.head(10))
# 
# st.subheader("Statistics Summary")
# summary_cols = ["sale_date", "price", "num_bedrooms", "num_bathrooms", "living_sqft", "year_built"]
# available_cols = [c for c in summary_cols if c in f.columns]
# if not f.empty and available_cols:
#     st.write(f[available_cols].describe(include="all"))
# else:
#     st.info("No data available for the selected filters.")
# 
# st.markdown("---")
# st.markdown("**Data Source:** House Sales in King County, USA (from Kaggle)")
# 
# 
# # ðŸ’¬ House Price Prediction Chatbot
# 
# st.header("ðŸ’¬ House Price Prediction Chatbot")
# with st.expander("How to use the chatbot (click to expand)"):
#     st.markdown("""
# Enter house details in one message. The chatbot will predict the price.
# 
# Example: `living=2000 grade=8 bath=2 bed=3 cond=4 wf=0 year=2015 month=6`
# """)
# 
# @st.cache_resource
# def load_artifacts():
#     with open("ols_model.pkl", "rb") as f:
#         ols_model = pickle.load(f)
#     with open("trend_train.pkl", "rb") as f:
#         trend_train = pickle.load(f)  # dict-like {Period('YYYY-MM','M'): trend_value}
#     with open("meta.pkl", "rb") as f:
#         meta = pickle.load(f)  # expects keys: features, X_train_columns, last_trend
#     return ols_model, trend_train, meta
# 
# ols_model, trend_train, meta = load_artifacts()
# last_trend   = meta.get("last_trend", 0.0)
# features     = list(meta.get("features", []))
# X_train_cols = list(meta.get("X_train_columns", []))
# 
# def predict_price(living_sqft, grade, num_bathrooms, num_bedrooms,
#                   condition, waterfront, year, month):
# 
#     row = {
#         "living_sqft": living_sqft,
#         "grade": grade,
#         "num_bathrooms": num_bathrooms,
#         "num_bedrooms": num_bedrooms,
#         "condition": condition,
#         "waterfront": waterfront,
#     }
# 
# 
#     if "year" in features:
#         row["year"] = year
#     if "month" in features:
#         row["month"] = month
# 
#     df_row = pd.DataFrame([row]).astype(float)
# 
# 
#     ym = pd.Period(f"{int(year)}-{int(month):02d}", freq="M")
#     mt = trend_train.get(ym, last_trend) if hasattr(trend_train, "get") else last_trend
#     df_row["market_trend"] = float(mt)
# 
#     feature_list = features if len(features) else list(df_row.columns)
# 
#     X_no_const = df_row.reindex(columns=feature_list, fill_value=0.0).astype(float)
# 
# 
#     X = sm.add_constant(X_no_const, has_constant="add")
#     X = X.reindex(columns=X_train_cols, fill_value=0.0)
# 
# 
#     y_log = float(ols_model.predict(X).iloc[0])
#     smear = float(np.exp(getattr(ols_model, "mse_resid", 0) / 2.0))
#     return round(float(np.exp(y_log) * smear), 2)
# 
# def extract_float(key, text, default=None):
#     m = re.search(rf"{key}\s*=?\s*([-+]?\d*\.?\d+)", text, re.IGNORECASE)
#     return float(m.group(1)) if m else default
# 
# def extract_int(key, text, default=None):
#     val = extract_float(key, text, None)
#     return int(val) if val is not None else default
# 
# 
# if "chat" not in st.session_state:
#     st.session_state.chat = [
#         {"role": "assistant", "content": "Hi! Enter house details (living, grade, bath, bed, cond, wf, year, month) and Iâ€™ll predict the price."}
#     ]
# 
# for m in st.session_state.chat:
#     with st.chat_message(m["role"]):
#         st.write(m["content"])
# 
# msg = st.chat_input("Type here, e.g. living=5000 grade=3 bath=3 bed=3 cond=3 wf=1 year=2026 month=4")
# if msg:
#     st.session_state.chat.append({"role": "user", "content": msg})
#     with st.chat_message("user"):
#         st.write(msg)
# 
#     living_sqft   = extract_float("living", msg, None)
#     grade         = extract_int("grade", msg, None)
#     num_bathrooms = extract_int("bath", msg, None)
#     num_bedrooms  = extract_int("bed", msg, None)
#     condition     = extract_int("cond", msg, None)
#     waterfront    = extract_int("wf", msg, None)
#     year          = extract_int("year", msg, None)
#     month         = extract_int("month", msg, None)
# 
#     values = {
#         "living_sqft": living_sqft, "grade": grade, "num_bathrooms": num_bathrooms,
#         "num_bedrooms": num_bedrooms, "condition": condition, "waterfront": waterfront,
#         "year": year, "month": month
#     }
#     missing = [k for k,v in values.items() if v is None]
# 
#     if missing:
#         reply = "Missing fields: **" + ", ".join(missing) + "**"
#     else:
#         try:
#             pred = predict_price(**values)
#             reply = f"Predicted Price: **${pred:,.2f}**"
#         except Exception as e:
#             reply = f"Error: {e}"
# 
#     st.session_state.chat.append({"role": "assistant", "content": reply})
#     with st.chat_message("assistant"):
#         st.write(reply)
#

!pip install -q streamlit pyngrok # Install Streamlit and ngrok

from getpass import getpass
from pyngrok import ngrok, conf
import os, time, subprocess


print("Enter your ngrok authtoken (input hidden):")
authtoken = getpass()

conf.get_default().auth_token = authtoken


ngrok.kill()


subprocess.Popen(
    ["streamlit", "run", "dashboard.py", "--server.port", "8501", "--server.headless", "true"],
    stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT
)
time.sleep(2)


tunnel = ngrok.connect(8501, "http")
print("Streamlit app is live at:", tunnel.public_url)

